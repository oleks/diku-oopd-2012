\chapter{Generics}

% Fluency prerequisites:
%
% Subtype polymorphism.
% Type casting.

Sometimes subtype polymorphism doesn't quite cut it. This is best illustrated
by an example. Consider building an \mono{AggregateCollection}, capable of
collecting any reference type. Let the collection have the following methods:

\begin{codebox}
\Procname{\mono{uint AggregateCollection::Length()}}
\end{codebox}

\begin{codebox}
\Procname{\code{void AggregateCollection::Append(T value)}}
\zi \kw{before} $\textt{\kw{this}.length} = n$
\zi \kw{after} $\left\{
\begin{array}{l}
\textt{\kw{this}.length} = n + 1\\
\textt{\kw{this}.Get(n)} = \textt{value}
\end{array}
\right.$
\end{codebox}

\begin{codebox}
\Procname{\mono{T AggregateCollection::Get(uint index)}}
\end{codebox}

Here the type \code{T} is used as a placeholder, and is not a built-in, or
user-defined type.  The question is -- what type should type \code{T} be? Our
requirement was that the collection can collect any reference type. We know
that there is a supertype to all reference types in our system, namely
\code{Object}, and that our system has subtype polymorphism.  Shouldn't we then
simply use \code{Object} in place of \code{T}?

We could, but this has at lest two logical pitfalls. Firstly, as far as the
type system is concerned, any element that we get from the collection is merely
just that -- an \code{Object}. That is, we can append an instance of any
reference type to the collection, but as soon as we do that, we lose precious
type information about that element. Secondly, we have no guarantee that all
the elements of a collection share any supertype other than \code{Object}.
Hence we cannot with all confidence cast an element to \emph{any} other type.

This loss of formality can be na\"ively mitigated for using a naming
convention. For instance, all \code{AggregateCollection}s of \code{String}s get
the prefix \code{StringCollection}. If all programmers follow this convention,
then it is supposedly safe to cast any element we get from a collection who's
name is prefixed with \code{StringCollection} to the ``appropriate'' subtype,
i.e. \mono{String}.

Naturally, this is notoriously error prone. This is a case of the, common to
programmers, surrender to convention over a formal extension of the language
semantics, leaving considerable room for logical errors.

The immediate alternative is to copy and paste the collection code for every
type that we might wish to collect, thereby declaring a collection type for
each collected type. This is yet another case of the surrender to convention
over an extension of the language semantics, and is just as error prone, and by
magnitudes more boring\footnote{Especially given the fact the number of such
types is countably infinite.} and dirty.

Surely there must be a way to automate this process, with some sort of template technique.

 and sure
enough, we figured it out back in the
1970's\cite{the-c++-programming-language}. The technique is formally called
\key{parametric polymorphism}, but has the generally accepted popular names of
\key{template programming} and \key{generic programming}.

Object-oriented languages generally posses a special type of parametric
polymorphism. In particular, the parameters limit only the supertype of the
possible objects, and there are means to limit the types of parameters with
various constraints, for instance, that they implement some sequence of
interfaces.

\newpage


The requirement of generics is akin to so many other problems in computer
science, where the type system is extended to ensure that certain logical
errors are be avoided at runtime.

Wrt. structured programming -- it is not an extension of the type system -- it
is an extension of the language semantics with the intent to ensure that
certain logical errors (that arise with the use of say goto statements) are
avoided at runtime. Hence, this behaviour is observed not only in type system
extensions, but elsewhere as well.
